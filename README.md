# ğŸ§  Tutorial GuÃ­ado: TensorFlow Lite con Python

## ğŸ¯ Objetivo
Instalar TensorFlow Lite y ejecutar un modelo de ejemplo de clasificaciÃ³n de imÃ¡genes desde Python. Este tutorial estÃ¡ pensado para principiantes y dispositivos con recursos limitados (como Raspberry Pi).

---

## ğŸ§° Requisitos

- âœ… Python 3.8 a 3.12 instalado
- âœ… Acceso a terminal o consola
- âœ… ConexiÃ³n a internet
- âœ… Funciona en Windows, Linux, Raspberry Pi OS

---

## âœ… Paso 1: Crear un entorno virtual (opcional pero recomendado)

### En Windows / Linux / Raspberry Pi:

```bash
python -m venv tflite_env
```

Activamos el entorno:

**En Windows**

```bash
tflite_env\Scripts\activate
```

**En Linux**

```bash
source tflite_env/bin/activate
```

## âœ… Paso 2: Instalar TensorFlow Lite

Instalamos el paquete correspondiente:

```bash
pip install tflite-runtime
```

## âœ… Paso 3: Descargamos el modelo preentrenado

Abrimos NANO y creamos un script de Python:

```bash
nano download_model.py
```

Dentro de NANO escribimos:

```python
import urllib.request

MODEL_URL = "https://storage.googleapis.com/download.tensorflow.org/models/tflite/model_mobilenet_v1_1.0_224_quant.tflite"
MODEL_PATH = "mobilenet_v1.tflite"

urllib.request.urlretrieve(MODEL_URL, MODEL_PATH)

print("Modelo descargado como mobilenet_v1.tflite")
```
Ejecutamos:

```bash
python download_model.py
```

## âœ… Paso 4: Descargamos el modelo preentrenado

Abrimos NANO y creamos un script de Python:

```bash
nano download_image.py
```

Dentro de NANO escribimos:

```python
import urllib.request

IMAGE_URL = "https://tensorflow.org/images/grace_hopper.jpg"
urllib.request.urlretrieve(IMAGE_URL, "grace_hopper.jpg")

print("Imagen descargada")
```

Ejecutamos:

```bash
python download_image.py
```
## âœ… Paso 5: Ejecutar el modelo con TensorFlow Lite

Abrimos NANO y creamos un script de Python:

```bash
nano run_model.py
```
Dentro de NANO escribimos:

```python
import numpy as np
from PIL import Image
import tflite_runtime.interpreter as tflite

# Cargar modelo
interpreter = tflite.Interpreter(model_path="mobilenet_v1.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Preparar imagen
img = Image.open("grace_hopper.jpg").resize((224, 224))
input_data = np.expand_dims(np.array(img, dtype=np.uint8), axis=0)

# Inferencia
interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
output = interpreter.get_tensor(output_details[0]['index'])

# Mostrar resultado
top_index = np.argmax(output)
print(f"PredicciÃ³n (Ã­ndice): {top_index}")
```

Ejecutamos:

```bash
python run_model.py
```

Resultado Final:

DespuÃ©s de ejecutar todos los pasos debemos obtener un nÃºmero en la consola por ejemplo:

```scss
PredicciÃ³n (Ã­ndice): 653
```

Este nÃºmero representa la categorÃ­a predicha por el modelo y comprueba el funcionamiento adecuado de la herramienta.


# Opcional: Etiequetas reales: 

Abre en terminal el siguiente paquete:

```bash
wget https://storage.googleapis.com/download.tensorflow.org/data/imagenet_labels.txt
```
Luego abre el archivo *imagenet_labels.txt* y busca la lÃ­nea con el Ã­ndice.


## ğŸ“ Consejos

- âœ… AsegÃºrate de tener activado el entorno virtual al instalar o ejecutar los scripts.
- ğŸ“‚ Todos los archivos `.py`, `.tflite` e imagen deben estar en la **misma carpeta**.
- ğŸ› ï¸ Si algo falla, repite el paso anterior o revisa si hubo errores en la consola.

---

## ğŸ“š Â¿QuÃ© aprendiste?

- ğŸ“¦ Instalar TensorFlow Lite en un entorno liviano  
- ğŸ” Descargar y usar un modelo preentrenado  
- ğŸ–¼ï¸ Ejecutar inferencia en una imagen  
- ğŸš« Todo sin necesidad de GPU o conexiÃ³n a la nube









